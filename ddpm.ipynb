{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCiiBzw5qtGN",
        "outputId": "5debc641-d73d-4730-be8b-975c8a08bbb3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFfLmyRZtB3a",
        "outputId": "5d7c4c86-4bf0-4dcc-b695-c76fead23544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DDPM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "965iEmdksiFf"
      },
      "outputs": [],
      "source": [
        "# Hyperparams\n",
        "BATCH_SIZE = 128  # according to the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm0j5FCVxALY",
        "outputId": "37cfa406-72d3-4e64-aa38-e96f8e4e04bb"
      },
      "outputs": [],
      "source": [
        "# CIFAR10\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5,), (0.5,)),\n",
        "#     transforms.RandomHorizontalFlip()  # p=0.5 by default\n",
        "# ])\n",
        "\n",
        "# train = datasets.CIFAR10(\"../data\", train=True, download=True, transform=transform)\n",
        "# test = datasets.CIFAR10(\"../data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zPLusxnzrXzh"
      },
      "outputs": [],
      "source": [
        "# MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train = datasets.MNIST(\"../data\", train=True, download=True, transform=transform) # 28x28 resolution\n",
        "test = datasets.MNIST(\"../data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing UNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.1+cu128\n",
            "3.10.8\n",
            "cuda:0\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGrNJREFUeJzt3X9sVfX9x/HXLdALantrqe3tlYIFRDb5sQ2ha1S+OBpKlxBRlgnyBxgCA4sZMIeBqOh+pBtLnHPp8J+FzkTQsQlEkrFAsWW6AgEhDdtsaNcJBFomWe+FIoW1n+8fxDuvFPBc7u279/J8JCeh955Pz9uzO5497eXU55xzAgCgj2VYDwAAuDURIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGKg9QBf1NPTo1OnTikrK0s+n896HACAR845nTt3TqFQSBkZ177O6XcBOnXqlIqKiqzHAADcpBMnTmjYsGHXfL7ffQsuKyvLegQAQALc6O/zpAWourpa99xzjwYPHqySkhIdOHDgS63j224AkB5u9Pd5UgL09ttva9WqVVq3bp0+/PBDTZw4UeXl5Tpz5kwyDgcASEUuCaZMmeIqKyujH3d3d7tQKOSqqqpuuDYcDjtJbGxsbGwpvoXD4ev+fZ/wK6BLly7p0KFDKisriz6WkZGhsrIyNTQ0XLV/V1eXIpFIzAYASH8JD9Ann3yi7u5uFRQUxDxeUFCgtra2q/avqqpSIBCIbrwDDgBuDebvgluzZo3C4XB0O3HihPVIAIA+kPB/B5SXl6cBAwaovb095vH29nYFg8Gr9vf7/fL7/YkeAwDQzyX8CigzM1OTJk1SbW1t9LGenh7V1taqtLQ00YcDAKSopNwJYdWqVVqwYIEeeOABTZkyRa+++qo6Ozv11FNPJeNwAIAUlJQAPfHEE/r3v/+tF198UW1tbfra176mnTt3XvXGBADArcvnnHPWQ3xeJBJRIBCwHgMAcJPC4bCys7Ov+bz5u+AAALcmAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIuEBeumll+Tz+WK2sWPHJvowAIAUNzAZn/T+++/X7t27/3eQgUk5DAAghSWlDAMHDlQwGEzGpwYApImk/Azo2LFjCoVCGjlypObPn6/jx49fc9+uri5FIpGYDQCQ/hIeoJKSEtXU1Gjnzp3asGGDWltb9fDDD+vcuXO97l9VVaVAIBDdioqKEj0SAKAf8jnnXDIP0NHRoREjRuiVV17RokWLrnq+q6tLXV1d0Y8jkQgRAoA0EA6HlZ2dfc3nk/7ugJycHI0ZM0bNzc29Pu/3++X3+5M9BgCgn0n6vwM6f/68WlpaVFhYmOxDAQBSSMID9Oyzz6q+vl7/+te/9Ne//lWPPfaYBgwYoHnz5iX6UACAFJbwb8GdPHlS8+bN09mzZ3XXXXfpoYce0r59+3TXXXcl+lAAgBSW9DcheBWJRBQIBKzHQIrbvHlzXOt6eno8r5k/f35cxwLS3Y3ehMC94AAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE0n/hXRAKvnud7/rec26des8r7nWL2gEbiVcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEd8NGv5eTk+N5zXe+8524juXz+TyviWe+0aNHe17zve99z/OajIz4vsbcsWOH5zXvvfdeXMfCrYsrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjRVoaMGBAXOu6u7s9r5k+fbrnNVVVVZ7X9KUpU6Z4XvPwww8nYRKkM66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATPuecsx7i8yKRiAKBgPUY6EcyMrx/nfSHP/whrmPNnj07rnV9IRKJeF5z4MCBuI71yCOPeF6zdetWz2vmzZvneU08N4yFjXA4rOzs7Gs+zxUQAMAEAQIAmPAcoL1792rWrFkKhULy+Xzatm1bzPPOOb344osqLCzUkCFDVFZWpmPHjiVqXgBAmvAcoM7OTk2cOFHV1dW9Pr9+/Xq99tprev3117V//37dfvvtKi8v18WLF296WABA+vD8G1ErKipUUVHR63POOb366qt6/vnn9eijj0qS3njjDRUUFGjbtm2aO3fuzU0LAEgbCf0ZUGtrq9ra2lRWVhZ9LBAIqKSkRA0NDb2u6erqUiQSidkAAOkvoQFqa2uTJBUUFMQ8XlBQEH3ui6qqqhQIBKJbUVFRIkcCAPRT5u+CW7NmjcLhcHQ7ceKE9UgAgD6Q0AAFg0FJUnt7e8zj7e3t0ee+yO/3Kzs7O2YDAKS/hAaouLhYwWBQtbW10ccikYj279+v0tLSRB4KAJDiPL8L7vz582pubo5+3NraqiNHjig3N1fDhw/XihUr9JOf/ET33nuviouL9cILLygUCvXrW5wAAPqe5wAdPHgw5j5Rq1atkiQtWLBANTU1Wr16tTo7O7VkyRJ1dHTooYce0s6dOzV48ODETQ0ASHncjBT93u233+55zUcffRTXsYYNG+Z5TV/9X2jMmDGe11y4cCGuYzU1NXleE8//TvGc71OnTnleAxvcjBQA0C8RIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAhOdfxwD0taeeesrzmrvvvjuuY8VzZ+tPP/3U85p169Z5XtPS0uJ5zdy5cz2vkeK7szXgFVdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkaKfu/ee+/ts2N1d3d7XjN+/HjPa/75z396XtPfnT171vOarq6uJEyCVMEVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRok9VVlZ6XrNs2TLPa5xzntdI0tq1az2v6c83Fs3I6LuvMT/44APPa+K5gSnSB1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkaKuN15552e16xevdrzGp/P53nNqlWrPK+RpF/96ldxresLQ4YM8bwm3vMA9AWugAAAJggQAMCE5wDt3btXs2bNUigUks/n07Zt22KeX7hwoXw+X8w2c+bMRM0LAEgTngPU2dmpiRMnqrq6+pr7zJw5U6dPn45umzdvvqkhAQDpx/ObECoqKlRRUXHdffx+v4LBYNxDAQDSX1J+BlRXV6f8/Hzdd999WrZs2XV/7W5XV5cikUjMBgBIfwkP0MyZM/XGG2+otrZWP//5z1VfX6+Kigp1d3f3un9VVZUCgUB0KyoqSvRIAIB+KOH/Dmju3LnRP48fP14TJkzQqFGjVFdXp+nTp1+1/5o1a2L+rUIkEiFCAHALSPrbsEeOHKm8vDw1Nzf3+rzf71d2dnbMBgBIf0kP0MmTJ3X27FkVFhYm+1AAgBTi+Vtw58+fj7maaW1t1ZEjR5Sbm6vc3Fy9/PLLmjNnjoLBoFpaWrR69WqNHj1a5eXlCR0cAJDaPAfo4MGDeuSRR6Iff/bzmwULFmjDhg1qbGzU7373O3V0dCgUCmnGjBn68Y9/LL/fn7ipAQApz3OApk2bJufcNZ//85//fFMDIXVc73WQyDU1NTWe1/Tnm4rGq7i42POar3/960mYpHfvvPNOnx0L6YF7wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEwn8lN24dHR0dntcsX77c85q//OUvntekoyVLlvTZsf7zn/94XlNfX5+ESZDOuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1L0qR07dliPkLLGjBnTZ8eKRCKe13z88cdJmATpjCsgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAENyMFDDzwwAOe15SXlydhkt7t3r27z46FWxdXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GChhYu3at5zU+n8/zmvr6es9rJOnpp5+Oax3gBVdAAAATBAgAYMJTgKqqqjR58mRlZWUpPz9fs2fPVlNTU8w+Fy9eVGVlpYYOHao77rhDc+bMUXt7e0KHBgCkPk8Bqq+vV2Vlpfbt26ddu3bp8uXLmjFjhjo7O6P7rFy5Uu+++662bNmi+vp6nTp1So8//njCBwcApDZPb0LYuXNnzMc1NTXKz8/XoUOHNHXqVIXDYf32t7/Vpk2b9K1vfUuStHHjRn3lK1/Rvn379M1vfjNxkwMAUtpN/QwoHA5LknJzcyVJhw4d0uXLl1VWVhbdZ+zYsRo+fLgaGhp6/RxdXV2KRCIxGwAg/cUdoJ6eHq1YsUIPPvigxo0bJ0lqa2tTZmamcnJyYvYtKChQW1tbr5+nqqpKgUAguhUVFcU7EgAghcQdoMrKSh09elRvvfXWTQ2wZs0ahcPh6HbixImb+nwAgNQQ1z9EXb58uXbs2KG9e/dq2LBh0ceDwaAuXbqkjo6OmKug9vZ2BYPBXj+X3++X3++PZwwAQArzdAXknNPy5cu1detW7dmzR8XFxTHPT5o0SYMGDVJtbW30saamJh0/flylpaWJmRgAkBY8XQFVVlZq06ZN2r59u7KysqI/1wkEAhoyZIgCgYAWLVqkVatWKTc3V9nZ2XrmmWdUWlrKO+AAADE8BWjDhg2SpGnTpsU8vnHjRi1cuFCS9Mtf/lIZGRmaM2eOurq6VF5ert/85jcJGRYAkD48Bcg5d8N9Bg8erOrqalVXV8c9FJDu+urdnjt27Ihr3eXLlxM8CXA17gUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE3H9RlQA/zN69GjPa0aNGuV5TWdnp+c1u3bt8rwG6CtcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKXCT8vLyPK/JycnxvOatt97yvKaxsdHzGqCvcAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTA52RkeP+abO3atUmY5Go//elP++Q4QF/hCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSIHPiedmpKNHj/a85o9//KPnNR999JHnNUB/xhUQAMAEAQIAmPAUoKqqKk2ePFlZWVnKz8/X7Nmz1dTUFLPPtGnT5PP5YralS5cmdGgAQOrzFKD6+npVVlZq37592rVrly5fvqwZM2aos7MzZr/Fixfr9OnT0W39+vUJHRoAkPo8vQlh586dMR/X1NQoPz9fhw4d0tSpU6OP33bbbQoGg4mZEACQlm7qZ0DhcFiSlJubG/P4m2++qby8PI0bN05r1qzRhQsXrvk5urq6FIlEYjYAQPqL+23YPT09WrFihR588EGNGzcu+viTTz6pESNGKBQKqbGxUc8995yampr0zjvv9Pp5qqqq9PLLL8c7BgAgRfmccy6ehcuWLdOf/vQnvf/++xo2bNg199uzZ4+mT5+u5uZmjRo16qrnu7q61NXVFf04EomoqKgonpGAmzZwoPevyRobGz2v+dvf/uZ5zdy5cz2v6e7u9rwGSJRwOKzs7OxrPh/XFdDy5cu1Y8cO7d2797rxkaSSkhJJumaA/H6//H5/PGMAAFKYpwA55/TMM89o69atqqurU3Fx8Q3XHDlyRJJUWFgY14AAgPTkKUCVlZXatGmTtm/frqysLLW1tUmSAoGAhgwZopaWFm3atEnf/va3NXToUDU2NmrlypWaOnWqJkyYkJT/AABAavIUoA0bNki68o9NP2/jxo1auHChMjMztXv3br366qvq7OxUUVGR5syZo+effz5hAwMA0oPnb8FdT1FRkerr629qIADArYG7YQOf89///tfzmq9+9atJmARIf9yMFABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP9LkDOOesRAAAJcKO/z/tdgM6dO2c9AgAgAW7097nP9bNLjp6eHp06dUpZWVny+Xwxz0UiERUVFenEiRPKzs42mtAe5+EKzsMVnIcrOA9X9Ifz4JzTuXPnFAqFlJFx7eucgX0405eSkZGhYcOGXXef7OzsW/oF9hnOwxWchys4D1dwHq6wPg+BQOCG+/S7b8EBAG4NBAgAYCKlAuT3+7Vu3Tr5/X7rUUxxHq7gPFzBebiC83BFKp2HfvcmBADArSGlroAAAOmDAAEATBAgAIAJAgQAMJEyAaqurtY999yjwYMHq6SkRAcOHLAeqc+99NJL8vl8MdvYsWOtx0q6vXv3atasWQqFQvL5fNq2bVvM8845vfjiiyosLNSQIUNUVlamY8eO2QybRDc6DwsXLrzq9TFz5kybYZOkqqpKkydPVlZWlvLz8zV79mw1NTXF7HPx4kVVVlZq6NChuuOOOzRnzhy1t7cbTZwcX+Y8TJs27arXw9KlS40m7l1KBOjtt9/WqlWrtG7dOn344YeaOHGiysvLdebMGevR+tz999+v06dPR7f333/feqSk6+zs1MSJE1VdXd3r8+vXr9drr72m119/Xfv379ftt9+u8vJyXbx4sY8nTa4bnQdJmjlzZszrY/PmzX04YfLV19ersrJS+/bt065du3T58mXNmDFDnZ2d0X1Wrlypd999V1u2bFF9fb1OnTqlxx9/3HDqxPsy50GSFi9eHPN6WL9+vdHE1+BSwJQpU1xlZWX04+7ubhcKhVxVVZXhVH1v3bp1buLEidZjmJLktm7dGv24p6fHBYNB94tf/CL6WEdHh/P7/W7z5s0GE/aNL54H55xbsGCBe/TRR03msXLmzBknydXX1zvnrvxvP2jQILdly5boPv/4xz+cJNfQ0GA1ZtJ98Tw459z//d//ue9///t2Q30J/f4K6NKlSzp06JDKysqij2VkZKisrEwNDQ2Gk9k4duyYQqGQRo4cqfnz5+v48ePWI5lqbW1VW1tbzOsjEAiopKTklnx91NXVKT8/X/fdd5+WLVums2fPWo+UVOFwWJKUm5srSTp06JAuX74c83oYO3ashg8fntavhy+eh8+8+eabysvL07hx47RmzRpduHDBYrxr6nc3I/2iTz75RN3d3SooKIh5vKCgQB999JHRVDZKSkpUU1Oj++67T6dPn9bLL7+shx9+WEePHlVWVpb1eCba2tokqdfXx2fP3Spmzpypxx9/XMXFxWppadHatWtVUVGhhoYGDRgwwHq8hOvp6dGKFSv04IMPaty4cZKuvB4yMzOVk5MTs286vx56Ow+S9OSTT2rEiBEKhUJqbGzUc889p6amJr3zzjuG08bq9wHC/1RUVET/PGHCBJWUlGjEiBH6/e9/r0WLFhlOhv5g7ty50T+PHz9eEyZM0KhRo1RXV6fp06cbTpYclZWVOnr06C3xc9DrudZ5WLJkSfTP48ePV2FhoaZPn66WlhaNGjWqr8fsVb//FlxeXp4GDBhw1btY2tvbFQwGjabqH3JycjRmzBg1Nzdbj2Lms9cAr4+rjRw5Unl5eWn5+li+fLl27Nih9957L+bXtwSDQV26dEkdHR0x+6fr6+Fa56E3JSUlktSvXg/9PkCZmZmaNGmSamtro4/19PSotrZWpaWlhpPZO3/+vFpaWlRYWGg9ipni4mIFg8GY10ckEtH+/ftv+dfHyZMndfbs2bR6fTjntHz5cm3dulV79uxRcXFxzPOTJk3SoEGDYl4PTU1NOn78eFq9Hm50Hnpz5MgRSepfrwfrd0F8GW+99Zbz+/2upqbG/f3vf3dLlixxOTk5rq2tzXq0PvWDH/zA1dXVudbWVvfBBx+4srIyl5eX586cOWM9WlKdO3fOHT582B0+fNhJcq+88oo7fPiw+/jjj51zzv3sZz9zOTk5bvv27a6xsdE9+uijrri42H366afGkyfW9c7DuXPn3LPPPusaGhpca2ur2717t/vGN77h7r33Xnfx4kXr0RNm2bJlLhAIuLq6Onf69OnoduHCheg+S5cudcOHD3d79uxxBw8edKWlpa60tNRw6sS70Xlobm52P/rRj9zBgwdda2ur2759uxs5cqSbOnWq8eSxUiJAzjn361//2g0fPtxlZma6KVOmuH379lmP1OeeeOIJV1hY6DIzM93dd9/tnnjiCdfc3Gw9VtK99957TtJV24IFC5xzV96K/cILL7iCggLn9/vd9OnTXVNTk+3QSXC983DhwgU3Y8YMd9ddd7lBgwa5ESNGuMWLF6fdF2m9/fdLchs3bozu8+mnn7qnn37a3Xnnne62225zjz32mDt9+rTd0Elwo/Nw/PhxN3XqVJebm+v8fr8bPXq0++EPf+jC4bDt4F/Ar2MAAJjo9z8DAgCkJwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxP8D2LKGo5qYGvEAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ddpm import Unet\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "image,label = next(dataiter)\n",
        "#plt.imshow(image[0].squeeze().numpy(),cmap='gray')\n",
        "plt.imshow(image[0][0].numpy(),cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Unet(1)\n",
        "output = model(image[0].unsqueeze(0), t=torch.tensor([1]))\n",
        "plt.imshow(output.squeeze().squeeze().detach().numpy(),cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ddpm import DDPM\n",
        "model = DDPM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m images=images.to(device)\n\u001b[32m     13\u001b[39m optimizer.zero_grad()  \u001b[38;5;66;03m#zero gradients\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m pred_noise, true_noise = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(pred_noise.size())\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(images.size())\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/ddpm.py:190\u001b[39m, in \u001b[36mDDPM.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    188\u001b[39m noise = torch.randn(x.shape, device=x.device)\n\u001b[32m    189\u001b[39m noisy_img = \u001b[38;5;28mself\u001b[39m.diffusion_kernel(x, t, noise)\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m pred_noise=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepsilon_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pred_noise, noise\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/ddpm.py:137\u001b[39m, in \u001b[36mUnet.forward\u001b[39m\u001b[34m(self, x, t)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,t):\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Get time embedding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     time_embedding=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     x=\u001b[38;5;28mself\u001b[39m.proj(x)\n\u001b[32m    140\u001b[39m     skip_connection = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/main/training/ddpm/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)"
          ]
        }
      ],
      "source": [
        "# train\n",
        "LR = 2e-3\n",
        "NUM_EPOCH = 1\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=LR)\n",
        "\n",
        "for epoch in range(NUM_EPOCH):\n",
        "    model.train()\n",
        "    tot_loss=0.0\n",
        "    \n",
        "    for images,_ in train_loader:\n",
        "        images=images.to(device)\n",
        "        optimizer.zero_grad()  #zero gradients\n",
        "        pred_noise, true_noise = model(images)\n",
        "        print(pred_noise.size())\n",
        "        print(images.size())\n",
        "        loss = model.loss()\n",
        "        loss.backward() #backprop\n",
        "        optimizer.step()#update weights\n",
        "        tot_loss+=loss.item()#accumulate loss\n",
        "        \n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        images=images.to(device)\n",
        "        pred_noise, true_noise=model(images)\n",
        "        loss=model.loss(pred_noise, true_noise)\n",
        "        test_loss+=loss.item()\n",
        "\n",
        "print(f\"Test Loss:,{test_loss:.4f}\")\n",
        "\n",
        "# Visualize Reconstructions\n",
        "test_images, _ = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    reconstructions = model(test_images.to(device))\n",
        "\n",
        "# Plot original and reconstructed images\n",
        "fig, axes = plt.subplots(2, 8, figsize=(12, 4))\n",
        "for i in range(8):\n",
        "    axes[0, i].imshow(test_images[i][0].cpu().numpy(), cmap='gray')\n",
        "    axes[1, i].imshow(reconstructions[i][0].cpu().detach().numpy(), cmap='gray')\n",
        "    axes[0, i].axis('off')\n",
        "    axes[1, i].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import vae\n",
        "from vae import VAE \n",
        "# Synthetic forward-pass test (no dataset)\n",
        "LATENT_DIM=64\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "vae_model = VAE(1,LATENT_DIM).to(device)\n",
        "\n",
        "output = vae_model(image[0].unsqueeze(0).to(device))[0]\n",
        "plt.imshow(output.squeeze().squeeze().detach().cpu().numpy(),cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Hyperparams\n",
        "LR=2e-3\n",
        "NUM_EPOCHS=1\n",
        "optimizer = optim.Adam(vae_model.parameters(),lr=LR)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    vae_model.train()\n",
        "    tot_loss=0.0\n",
        "    \n",
        "    for images,_ in train_loader:\n",
        "        images=images.to(device)\n",
        "        optimizer.zero_grad()#zero gradients\n",
        "        recon,mean,logvar = vae_model(images)\n",
        "        print(recon.size())\n",
        "        print(images.size())\n",
        "        loss = vae_model.loss(recon,images,mean,logvar,beta=1.0)\n",
        "        loss.backward() #backprop\n",
        "        optimizer.step()#update weights\n",
        "        tot_loss+=loss.item()#accumulate loss\n",
        "        \n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        images=images.to(device)\n",
        "        recon=vae_model(images)\n",
        "        mean,logvar=model.encode(images)\n",
        "        loss=model.loss(recon, images, mean, logvar, beta=1.0)\n",
        "        test_loss+=loss.item()\n",
        "\n",
        "print(f\"Test Loss:,{test_loss:.4f}\")\n",
        "\n",
        "# Visualize Reconstructions\n",
        "test_images, _ = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    reconstructions = vae_model(test_images.to(device))\n",
        "\n",
        "# Plot original and reconstructed images\n",
        "fig, axes = plt.subplots(2, 8, figsize=(12, 4))\n",
        "for i in range(8):\n",
        "    axes[0, i].imshow(test_images[i][0].cpu().numpy(), cmap='gray')\n",
        "    axes[1, i].imshow(reconstructions[i][0].cpu().detach().numpy(), cmap='gray')\n",
        "    axes[0, i].axis('off')\n",
        "    axes[1, i].axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LDM"
      ]
    }
  ],
  "metadata": {
    "colab": {},
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
